{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Preditiva de Churn para Academias\n",
    "\n",
    "**Objetivo:** Construir um modelo de Machine Learning para prever a probabilidade de churn de clientes em uma academia, utilizando um dataset de exemplo (Telco Customer Churn) como base para a estrutura da análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "\n",
    "# Configurações de visualização\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento dos Dados\n",
    "\n",
    "Carregando o dataset de exemplo. Em um cenário real, substituir pelo dataset específico da academia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o arquivo CSV (ajuste se necessário)\n",
    "data_path = '../data/raw/telco_churn_sample.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"Dataset carregado com sucesso!\")\n",
    "    print(f\"Shape do dataset: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo não encontrado em {data_path}\")\n",
    "    # Em um caso real, tratar o erro apropriadamente\n",
    "    df = pd.DataFrame() # Cria um DataFrame vazio para evitar erros posteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar as primeiras linhas e informações básicas\n",
    "if not df.empty:\n",
    "    print(\"\nPrimeiras 5 linhas:\")\n",
    "    print(df.head())\n",
    "    print(\"\nInformações do Dataset:\")\n",
    "    print(df.info())\n",
    "    print(\"\nEstatísticas Descritivas:\")\n",
    "    print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise Exploratória de Dados (EDA)\n",
    "\n",
    "Nesta seção, exploramos os dados para entender melhor as distribuições, relações entre variáveis e identificar padrões iniciais relacionados ao churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores ausentes\n",
    "if not df.empty:\n",
    "    print(\"\nValores Ausentes por Coluna:\")\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza inicial (exemplo: converter TotalCharges para numérico, tratando erros)\n",
    "if 'TotalCharges' in df.columns:\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "    # Preencher valores ausentes em TotalCharges (ex: com a mediana ou média)\n",
    "    if df['TotalCharges'].isnull().any():\n",
    "        median_total_charges = df['TotalCharges'].median()\n",
    "        df['TotalCharges'].fillna(median_total_charges, inplace=True)\n",
    "        print(f\"Valores ausentes em TotalCharges preenchidos com a mediana: {median_total_charges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização da distribuição da variável alvo (Churn)\n",
    "if 'Churn' in df.columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x='Churn', data=df)\n",
    "    plt.title('Distribuição de Churn')\n",
    "    plt.show()\n",
    "    print(df['Churn'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Adicionar mais visualizações aqui:*\n",
    "    *   Histogramas para variáveis numéricas (ex: tenure, MonthlyCharges).\n",
    "    *   Gráficos de barras para variáveis categóricas (ex: Contract, PaymentMethod).\n",
    "    *   Boxplots para comparar distribuições numéricas por Churn.\n",
    "    *   Análise de correlação entre variáveis numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pré-processamento de Dados\n",
    "\n",
    "Preparação dos dados para a modelagem, incluindo tratamento de variáveis categóricas e escalonamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and 'Churn' in df.columns:\n",
    "    # Remover colunas irrelevantes (ex: customerID)\n",
    "    if 'customerID' in df.columns:\n",
    "        df_processed = df.drop('customerID', axis=1)\n",
    "    else:\n",
    "        df_processed = df.copy()\n",
    "\n",
    "    # Separar features (X) e variável alvo (y)\n",
    "    X = df_processed.drop('Churn', axis=1)\n",
    "    y = df_processed['Churn'].apply(lambda x: 1 if x == 'Yes' else 0) # Converter para binário\n",
    "\n",
    "    # Identificar colunas numéricas e categóricas\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "    print(f\"Features Numéricas: {list(numeric_features)}\")\n",
    "    print(f\"Features Categóricas: {list(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar transformadores para o pipeline\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Criar o pré-processador com ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Divisão dos Dados (Treino e Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and 'Churn' in df.columns:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(f\"Tamanho do conjunto de treino: {X_train.shape}, {y_train.shape}\")\n",
    "    print(f\"Tamanho do conjunto de teste: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Treinamento do Modelo\n",
    "\n",
    "Treinaremos alguns modelos de classificação usando Pipelines para incluir o pré-processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: Regressão Logística\n",
    "if not df.empty and 'Churn' in df.columns:\n",
    "    pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('classifier', LogisticRegression(random_state=42, max_iter=1000))])\n",
    "\n",
    "    pipeline_lr.fit(X_train, y_train)\n",
    "    print(\"Modelo de Regressão Logística treinado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: Random Forest\n",
    "if not df.empty and 'Churn' in df.columns:\n",
    "    pipeline_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "    pipeline_rf.fit(X_train, y_train)\n",
    "    print(\"Modelo Random Forest treinado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Adicionar outros modelos se desejar (ex: Gradient Boosting, SVM).*"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Avaliação dos Modelos\n",
    "\n",
    "Avaliamos o desempenho dos modelos no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Função para avaliar um modelo e imprimir métricas.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] # Probabilidade da classe positiva\n",
    "\n",
    "    print(f\"--- Avaliação: {model_name} ---\")\n",
    "    print(f\"Acurácia: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"AUC-ROC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(\"\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\nMatriz de Confusão:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.ylabel('Verdadeiro')\n",
    "    plt.title(f'Matriz de Confusão - {model_name}')\n",
    "    plt.show()\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar Regressão Logística\n",
    "if not df.empty and 'Churn' in df.columns:\n",
    "    evaluate_model(pipeline_lr, X_test, y_test, \"Regressão Logística\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar Random Forest\n",
    "if not df.empty and 'Churn' in df.columns:\n",
    "    evaluate_model(pipeline_rf, X_test, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusão e Próximos Passos\n",
    "\n",
    "Resumo dos resultados e sugestões para trabalhos futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Comparar os modelos e selecionar o melhor com base nas métricas relevantes (ex: AUC-ROC, Recall para a classe 'Churn').\n",
    "*   Realizar ajuste fino de hiperparâmetros (Hyperparameter Tuning) no melhor modelo.\n",
    "*   Analisar a importância das features (Feature Importance) para entender os drivers do churn.\n",
    "*   Interpretar o modelo (ex: usando SHAP ou LIME).\n",
    "*   Considerar técnicas para lidar com desbalanceamento de classe (ex: SMOTE, ajuste de pesos).\n",
    "*   Implantar o modelo final (ex: via API)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

